# -*- coding: utf-8 -*-
"""YoloV5_(Bounding_Boxes).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_uQrtXDFWeunpNzg9JqJTf6iF28NuwfX
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5
# %pip install -qr requirements.txt

import torch
import utils
display = utils.notebook_init()

!unzip -q /content/drive/MyDrive/weeds.zip -d /content/yolov5/

import os
import shutil
from sklearn.model_selection import train_test_split

# Paths
data_dir = '/content/yolov5/agri_data/data'
train_images_dir = '/content/yolov5/agri_data/train/images'
val_images_dir = '/content/yolov5/agri_data/val/images'
train_labels_dir = '/content/yolov5/agri_data/train/labels'
val_labels_dir = '/content/yolov5/agri_data/val/labels'

# Create directories
os.makedirs(train_images_dir, exist_ok=True)
os.makedirs(val_images_dir, exist_ok=True)
os.makedirs(train_labels_dir, exist_ok=True)
os.makedirs(val_labels_dir, exist_ok=True)

# Get list of images and corresponding labels
images = [f for f in os.listdir(data_dir) if f.endswith('.jpeg')]
labels = [f for f in os.listdir(data_dir) if f.endswith('.txt')]

# Split data into train and validation sets
train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)

# Copy files to respective directories
for img, lbl in zip(train_images, train_labels):
    shutil.copy(os.path.join(data_dir, img), train_images_dir)
    shutil.copy(os.path.join(data_dir, lbl), train_labels_dir)

for img, lbl in zip(val_images, val_labels):
    shutil.copy(os.path.join(data_dir, img), val_images_dir)
    shutil.copy(os.path.join(data_dir, lbl), val_labels_dir)

data_yaml_content = """
train: /content/yolov5/agri_data/train/images
val: /content/yolov5/agri_data/val/images

nc: 2
names: ['crop', 'weed']
"""
with open('/content/yolov5/data.yaml', 'w') as f:
    f.write(data_yaml_content)

# For Conversion
# !python export.py --weights best.pt --img 512 --include tflite

!python train.py --img 320 --batch 32 --epochs 20 --data /content/yolov5/data.yaml --weights yolov5s.pt --cache --name weed_detection

!python val.py --weights runs/train/weed_detection/weights/best.pt --data /content/yolov5/data.yaml --img 320

from IPython.display import Image, display

# Define the path to the confusion matrix image
confusion_matrix_path = 'runs/val/exp/confusion_matrix.png'

# Display the confusion matrix image
display(Image(filename=confusion_matrix_path))

"""# D

"""

!npm install localtunnel

# Start Streamlit app
!streamlit run app.py --server.port 8501 &>/content/logs.txt &

# Use localtunnel to create a public URL
!npx localtunnel --port 8501 > url.txt 2>&1 &

# Get the public URL
import time
time.sleep(5)  # Wait for the URL to be created
!cat url.txt

!curl https://loca.lt/mytunnelpassword