# -*- coding: utf-8 -*-
"""VGG_16_(Bounding_Boxes+Eval_Metrics).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SQPtkBsn91JPr7TgzwlkNpTSH6Tp8OGs
"""

import os
import json
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split

# Paths to the dataset
img_dir = '/content/drive/MyDrive/Mini-Project-Sem-4/Datasets/BOUNDING_BOXES_ALLINONE/agri_data/data'
classes_file = '/content/drive/MyDrive/Mini-Project-Sem-4/Datasets/BOUNDING_BOXES_ALLINONE/classes.txt'

# Loading class names
with open(classes_file, 'r') as f:
    classes = f.read().splitlines()
    classes = {i: cls for i, cls in enumerate(classes)}

# Loading images and annotations
def load_data(img_dir):
    images = []
    labels = []
    n = 0
    for img_name in os.listdir(img_dir):
        if img_name.endswith('.jpeg') or img_name.endswith('.png'):
            img_path = os.path.join(img_dir, img_name)
            ann_path = os.path.join(img_dir, os.path.splitext(img_name)[0] + '.txt')

            # Load image
            img = Image.open(img_path)
            img = img.resize((224, 224))
            images.append(np.array(img) / 255.0)  # Normalize to [0, 1]
            n += 1

            # Load annotation and set label (1 for weed, 0 for crop)
            with open(ann_path, 'r') as f:
                anns = f.read().strip().split('\n')
                is_weed = False
                for ann in anns:
                    cls_id = int(ann.split(' ')[0])
                    if classes[cls_id] == 'weed':
                        is_weed = True
                        break
                labels.append(1 if is_weed else 0)
    print(n, "images found")
    return np.array(images), np.array(labels)

# Loading the dataset
images, labels = load_data(img_dir)

X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)

# Data augmentation for training data
train_datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Data augmentation for validation data (only rescaling)
val_datagen = ImageDataGenerator()

# Create data generators
train_generator = train_datagen.flow(X_train, y_train, batch_size=32)
val_generator = val_datagen.flow(X_val, y_val, batch_size=32)

"""
# Model Training"""

# Load VGG16 model pre-trained on ImageNet, excluding top layers
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Adding custom top layers for binary classification
x = base_model.output
x = Flatten()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(1, activation='sigmoid')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# Create the optimizer without weight_decay or other unsupported parameters
optimizer = Adam(learning_rate=0.0001)

model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

# Callbacks
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = ModelCheckpoint('weed_detection_VGG-16_.keras', save_best_only=True, monitor='val_loss')

# Train the model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=15,
    callbacks=[early_stopping, model_checkpoint]
)

# Save the model
model.save('weed_detection_VGG-16_.h5')

"""# Evaluation Metrics"""

from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score

# Load the best model
model = tf.keras.models.load_model('weed_detection_VGG-16_.h5')

# Confusion Matrix
cm = confusion_matrix(y_val, np.argmax(model.predict(X_val), axis=-1))
print("Confusion Matrix:\n",cm)

# F1 Score
f1 = f1_score(y_val, np.argmax(model.predict(X_val), axis=-1), average='weighted')
print("F1 Score:", f1)

# Accuracy
accuracy = accuracy_score(y_val, np.argmax(model.predict(X_val), axis=-1))
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_val, np.argmax(model.predict(X_val), axis=-1), average='weighted')
print("Precision:", precision)

# Recall
recall = recall_score(y_val, np.argmax(model.predict(X_val), axis=-1), average='weighted')
print("Recall:", recall)

train_loss, train_acc = model.evaluate(train_generator)
val_loss, val_acc = model.evaluate(val_generator)

print(f"Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}")
print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}")

import numpy as np
from PIL import Image
import tensorflow as tf

# Function to load and preprocess a single image
def load_and_preprocess_image(img_path):
    img = Image.open(img_path)
    img = img.resize((224, 224))
    img = np.array(img) / 255.0  # Normalize to [0, 1]
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    return img

# Function to make a prediction on a single image
def predict_image(model, img_path):
    img = load_and_preprocess_image(img_path)
    display(Image.fromarray((img[0] * 255).astype(np.uint8)))
    prediction = model.predict(img)
    return np.argmax(prediction[0])

# An example image
example_img_path = '/content/drive/MyDrive/Mini-Project-Sem-4/Datasets/BOUNDING_BOXES_ALLINONE/agri_data/data/agri_0_177.jpeg'

# Load the model
model = tf.keras.models.load_model('weed_detection_VGG-16_.h5')

# Make a prediction
prediction = predict_image(model, example_img_path)


# Output the prediction
if prediction > 0.5:
    print(f"The image is predicted to be a weed with a probability of {prediction:.4f}")
else:
    print(f"The image is predicted to be a crop with a probability of {1 - prediction:.4f}")

"""# Deployment"""

# For Conversion
# Convert the model to TensorFlow Lite format
#converter = tf.lite.TFLiteConverter.from_keras_model(model)
#tflite_model = converter.convert()

# Save the TensorFlow Lite model
#with open('model.tflite', 'wb') as f:
#    f.write(tflite_model)